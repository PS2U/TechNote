# 5.1 动机

Spark 支持很多种输入输出源。一部分原因是 Spark 本身是基于 Hadoop 生态圈而构建，特别是 Spark 可以通过 Hadoop MapReduce 所使用的 `InputFormat` 和 `OutputFormat` 接口访问数据，而大部分常见的文件格式与存储系统（例如 S3、HDFS、Cassandra、HBase 等）都支持这种接口。

三类常见的数据源：

- **文件格式与文件系统**。对于存储在本地文件系统或分布式文件系统（比如 NFS、HDFS、Amazon S3 等）中的数据，Spark 可以访问很多种不同的文件格式，包括文本文件、JSON、SequenceFile，以及 protocol buffer。
- **Spark SQL中的结构化数据源**。针对JSON和Apache Hive。
- **数据库与键值存储**。连接如Cassandra、HBase、Elasticsearch、JDBC源。


# 5.2 文件格式 

