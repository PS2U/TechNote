Spark 可以在各种各样的集群管理器（Hadoop YARN、Apache Mesos，还有 Spark 自带的独立集群管理器）上运行，所以 Spark 应用既能够适应专用集群，又能用于共享的云计算环境。

# 7.2 Spark 运行时架构

![](img/chap7/img0.png)

在分布式环境下，Spark 集群采用的是**主/从**结构。在一个 Spark 集群中，有一个节点负责中央协调，调度各个分布式工作节点。这个中央协调节点被称为驱动器 （Driver）节点，与之对应的工作节点被称为执行器 （executor）节点。驱动器节点可以和大量的执行器节点进行通信，它们也都作为独立的 Java 进程运行。驱动器节点和所有的执行器节点一起被称为一个 Spark 应用 （application）。

Spark 应用通过一个叫作集群管理器 （Cluster Manager）的外部服务在集群中的机器上启动。Spark 自带的集群管理器被称为独立集群管理器。Spark 也能运行在 Hadoop YARN 和 Apache Mesos 这两大开源集群管理器上。

## 7.2.1 驱动器节点

Spark 驱动器是执行你的程序中的 `main()` 方法的进程。它执行用户编写的用来创建 SparkContext、创建 RDD，以及进行 RDD 的转化操作和行动操作的代码。其实，当你启动 Spark shell 时，你就启动了一个 Spark 驱动器程序。驱动器程序一旦终止，Spark 应用也就结束了。

驱动器程序在 Spark 应用中有两个职责：

- **把用户程序转换为任务**。

  Spark 程序其实是隐式地创建出了一个由操作组成的逻辑上的*有向无环图（Directed Acyclic Graph，简称 DAG）*。当驱动器程序运行时，它会把这个逻辑图转为物理执行计划。Spark 会对逻辑执行计划作一些优化，比如将连续的映射转为流水线化执行，将多个操作合并到一个步骤中等。这样 Spark 就把逻辑计划转为一系列*步骤（stage）*。而每个步骤又由多个*任务 (task)* 组成。这些任务会被打包并送到集群中。任务是 Spark 中最小的工作单元，用户程序通常要启动成百上千的独立任务。

- **为执行器节点调度任务**。

  执行器进程启动后，会向驱动器进程注册自己。因此，驱动器进程始终对应用中所有的执行器节点有完整的记录。每个执行器节点代表一个能够处理任务和存储 RDD 数据的进程。

  Spark 驱动器程序会根据当前的执行器节点集合，尝试把所有任务*基于数据所在位置*分配给合适的执行器进程。当任务执行时，执行器进程会把缓存数据存储起来，而驱动器进程同样会跟踪这些缓存数据的位置，并且利用这些位置信息来调度以后的任务，以尽量减少数据的网络传输。

  驱动器程序会将一些 Spark 应用的运行时的信息通过网页界面呈现出来，默认在端口 4040。

## 7.2.2 执行器节点

Spark 执行器节点是一种工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，执行器节点就被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有执行器节点发生了异常或崩溃，Spark 应用也可以继续执行。

执行器进程有两大作用：

- 负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；
- 通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在执行器进程内的，因此任务可以在运行时充分利用缓存数据加速运算。

## 7.2.3 集群管理器

Spark 依赖于集群管理器来启动执行器节点，而在某些特殊情况下，也依赖集群管理器来启动驱动器节点。集群管理器是 Spark 中的可插拔式组件。除了 Spark 自带的独立集群管理器，Spark 也可以运行在其他外部集群管理器上，比如 YARN 和 Mesos。

## 7.2.4 启动一个程序

不论你使用的是哪一种集群管理器，`spark-submit` 都可以你的应用提交到那种集群管理器上，并通过不同的配置选项控制应用所使用的资源数量。

## 7.2.5 小结

在集群上运行 Spark 应用的详细过程：

1. 用户通过 `spark-submit` 脚本提交应用。
2. `spark-submit` 脚本启动驱动器程序，调用用户定义的 `main()` 方法。
3. 驱动器程序与集群管理器通信，申请资源以启动执行器节点。
4. 集群管理器为驱动器程序启动执行器节点。
5. 驱动器进程执行用户应用中的操作。根据程序中所定义的对 RDD 的转化操作和行动操作，驱动器节点把工作以任务的形式发送到执行器进程。
6. 任务在执行器程序中进行计算并保存结果。
7. 如果驱动器程序的 `main()` 方法退出，或者调用了 `SparkContext.stop()` ，驱动器程序会终止执行器进程，并且通过集群管理器释放资源。

# 7.3 使用 `spark-submit` 部署

```shell 
bin/spark-submit [options] <app jar | python file> [app options]
```

> [options] 是要传给 spark-submit 的选项列表。
>
> \<app jar | python File> 表示包含应用入口的 JAR 包或 Python 脚本。
>
> [app options] 是传给你的应用的选项。如果你的程序要处理传给 `main()` 方法的参数，它只会得到 [app options] 对应的标记，不会得到 spark-submit 的标记。

`spark-submit`的一些常用选项：

| 选项                  | 描述                                       |
| ------------------- | ---------------------------------------- |
| `--master`          | 要连接的集群管理器                                |
| `--deploy-mode`     | 选择在本地（client）启动驱动器程序，还是在集群中的一台工作节点机器（cluster）上启动。 |
| `--class`           | 运行Scala的主类                               |
| `--name`            | 应用的显示名，在Spark的网页界面                       |
| `--jars`            | 需要上传并放到应用的 CLASSPATH 中的 JAR 包的列表。如果应用依赖于少量第三方的 JAR 包，可以把它们放在这个参数里 |
| `--files`           | 需要放到应用工作目录中的文件的列表。这个参数一般用来放需要分发到各节点的数据文件 |
| `--executor-memory` | 执行器进程使用的内存大小                             |
| `--driver-memory`   | 驱动器进程使用的内存大小                             |

`spark-submit` 还允许通过 `--conf prop=value` 标记设置任意的 SparkConf 配置选项，也可以使用 `--properties-File `指定一个包含键值对的属性文件。

# 7.4 打包代码与依赖

Scala 用户也可以通过 `spark-submit` 的 `--jars` 标记提交独立的 JAR 包依赖。当只有一两个库的简单依赖，并且这些库本身不依赖于其他库时，这种方法比较合适。

常规的做法是使用构建工具，生成单个大 JAR 包，包含应用的所有的传递依赖。Scala 使用 sbt 构建项目。

build.sbt: 
```
import AssemblyKeys._

name := "Simple Project"

version := "1.0"

organization := "com.databricks"

scalaVersion := "2.10.3"

libraryDependencies ++= Seq(
    // Spark依赖
    "org.apache.spark" % "spark-core_2.10" % "1.2.0" % "provided",
    // 第三方库
    "net.sf.jopt-simple" % "jopt-simple" % "4.3",
    "joda-time" % "joda-time" % "2.0"
)

// 这条语句打开了assembly插件的功能
assemblySettings

// 配置assembly插件所使用的JAR
jarName in assembly := "my-project-assembly.jar"

// 一个用来把Scala本身排除在组合JAR包之外的特殊选项，因为Spark
// 已经包含了Scala
assemblyOption in assembly :=
  (assemblyOption in assembly).value.copy(includeScala = false)
```

在 sbt 工程构建中添加 `assembly` 插件:

```shell
# 显示project/assembly.sbt的内容
$ cat project/assembly.sbt
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "0.11.2")
```

## 依赖冲突

当用户应用与 Spark 本身依赖同一个库时可能会发生依赖冲突，导致程序崩溃。通常，依赖冲突表现为 Spark 作业执行过程中抛出 `NoSuchMethodError` 、`ClassNotFoundException` ，或其他与类加载相关的 JVM 异常。

对于这种问题，主要有两种解决方式：

- 一是修改你的应用，使其使用的依赖库的版本与 Spark 所使用的相同
- 二是使用通常被称为『shading』的方式打包你的应用。『shading』可以让你以另一个命名空间保留冲突的包，并自动重写应用的代码使得它们使用重命名后的版本”


# 7.5 Spark 应用内与应用间调度

在调度多用户集群时，Spark 主要依赖*集群管理器*来在 Spark 应用间共享资源。当 Spark 应用向集群管理器申请执行器节点时，应用收到的执行器节点个数可能比它申请的更多或者更少，这取决于集群的可用性与争用。许多集群管理器支持队列，可以为队列定义不同优先级或容量限制，这样 Spark 就可以把作业提交到相应的队列中。

Spark 提供了一种用来配置应用内调度策略的机制。Spark 内部的[公平调度器 （Fair Scheduler）](http://spark.apache.org/docs/latest/job-scheduling.html)会让长期运行的应用定义调度任务的优先级队列。

# 7.6 集群管理器

Spark 可以运行在各种集群管理器上，并通过集群管理器访问集群中的机器。如果你只想在一堆机器上运行 Spark，那么自带的独立模式是部署该集群最简单的方法。然而，如果你有一个需要与别的分布式应用共享的集群（比如既可以运行 Spark 作业又可以运行 Hadoop MapReduce 作业），Spark 也可以运行在两个广泛使用的集群管理器——Hadoop YARN 与 Apache Mesos 上面。最后，在把 Spark 部署到 Amazon EC2 上时，Spark 有个自带的脚本可以启动独立模式集群以及各种相关服务。

## 7.6.1 独立集群管理器

独立集群管理器由一个*主节点*和几个*工作节点*组成，各自都分配有一定量的内存和 CPU 核心。当提交应用时，你可以配置执行器进程使用的内存量，以及所有执行器进程使用的 CPU 核心总数。

### 1. 启动集群管理器

要使用集群启动脚本，请按如下步骤执行。

1. 将编译好的 Spark 复制到所有机器的一个相同的目录下，比如 `/home/yourname/spark`。
2. 设置好从主节点机器到其他机器的 SSH 无密码登陆。这需要在所有机器上有相同的用户账号，并在主节点上通过 `ssh-keygen` 生成 SSH 私钥，然后将这个私钥放到所有工作节点的 `.ssh/authorized_keys` 文件中。
3. 编辑主节点的 `conf/slaves` 文件并填上所有工作节点的主机名。
4. 在主节点上运行 `sbin/start-all.sh` （**要在主节点上运行而不是在工作节点上**）以启动集群。如果全部启动成功，你不会得到需要密码的提示符，而且可以在 [http://masternode:8080](http://masternode:8080) 看到集群管理器的网页用户界面，上面显示着所有的工作节点。
5. 要停止集群，在主节点上运行 `bin/stop-all.sh` 。


启动集群的另一种办法：Spark 的 `bin/spark-class` 脚本分别手动启动主节点和工作节点。在主节点上，输入：
```shell 
bin/spark-class org.apache.spark.deploy.master.Master
```

然后在工作节点上输入：
```shell 
bin/spark-class org.apache.spark.deploy.worker.Worker spark://masternode:707”
```

默认情况下，集群管理器会选择合适的默认值自动为所有工作节点分配 CPU 核心与内存。

### 2. 提交应用

```
spark-submit --master spark://masternode:7077 yourapp
```

独立集群管理器支持两种部署模式 。在这两种模式中，应用的驱动器程序运行在不同的地方。

- 在客户端模式中（默认情况），驱动器程序会运行在你执行 `spark-submit` 的机器上，是 `spark-submit` 命令的一部分。这意味着你可以直接看到驱动器程序的输出，也可以直接输入数据进去（通过交互式 shell），但是这要求你提交应用的机器与工作节点间有很快的网络速度，并且在程序运行的过程中始终可用。
- 在集群模式下，驱动器程序会作为某个工作节点上一个独立的进程运行在独立集群管理器内部。它也会连接主节点来申请执行器节点。在这种模式下，`spark-submit` 是“一劳永逸”型，你可以在应用运行时关掉你的电脑。你还可以通过集群管理器的网页用户界面访问应用的日志。向 `spark-submit` 传递 `--deploy-mode cluster` 参数可以切换到集群模式。

### 3. 配置资源用量

独立集群管理器使用基础的调度策略，这种策略允许限制各个应用的用量来让多个应用并发执行。Apache Mesos 支持应用运行时的更动态的资源共享，而 YARN 则有分级队列的概念，可以让你限制不同类别的应用的用量。

在独立集群管理器中，资源分配靠下面两个设置来控制。

- 执行器进程内存

  你可以通过 `spark-submit` 的 `--executor-memory` 参数来配置此项。每个应用在每个工作节点上最多拥有一个执行器进程（一个机器可以运行多个节点），因此这个设置项能够控制执行器节点占用工作节点的多少内存。此设置项的默认值是 1 GB。

- 占用核心总数的最大值

   这是一个应用中所有执行器进程所占用的核心总数。此项的默认值是无限。也就是说，应用可以在集群所有可用的节点上启动执行器进程。你可以通过 `spark-submit` 的 `--total-executorcores` 参数设置这个值，或者在 Spark 配置文件中设置 `spark.cores.max` 的值。

最后，独立集群管理器在默认情况下会为每个应用使用尽可能分散的执行器进程。

### 4. 高度可用性

独立模式能够很好地支持工作节点的故障。如果你想让集群的主节点也拥有高度可用性，Spark 还支持使用 Apache ZooKeeper（一个分布式协调系统）来维护多个备用的主节点，并在一个主节点失败时切换到新的主节点上。

## 7.6.2 Hadoop YARN 

## 7.6.3 Hadoop Mesos


# 导航

[目录](README.md)

上一章：[6. Spark编程进阶](6. Spark编程进阶.md)

下一章：
