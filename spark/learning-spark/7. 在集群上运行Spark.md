Spark 可以在各种各样的集群管理器（Hadoop YARN、Apache Mesos，还有 Spark 自带的独立集群管理器）上运行，所以 Spark 应用既能够适应专用集群，又能用于共享的云计算环境。

# 7.2 Spark 运行时架构

![](img/chap7/img0.png)

在分布式环境下，Spark 集群采用的是**主/从**结构。在一个 Spark 集群中，有一个节点负责中央协调，调度各个分布式工作节点。这个中央协调节点被称为驱动器 （Driver）节点，与之对应的工作节点被称为执行器 （executor）节点。驱动器节点可以和大量的执行器节点进行通信，它们也都作为独立的 Java 进程运行。驱动器节点和所有的执行器节点一起被称为一个 Spark 应用 （application）。

Spark 应用通过一个叫作集群管理器 （Cluster Manager）的外部服务在集群中的机器上启动。Spark 自带的集群管理器被称为独立集群管理器。Spark 也能运行在 Hadoop YARN 和 Apache Mesos 这两大开源集群管理器上。

## 7.2.1 驱动器节点

Spark 驱动器是执行你的程序中的 `main()` 方法的进程。它执行用户编写的用来创建 SparkContext、创建 RDD，以及进行 RDD 的转化操作和行动操作的代码。其实，当你启动 Spark shell 时，你就启动了一个 Spark 驱动器程序。驱动器程序一旦终止，Spark 应用也就结束了。

驱动器程序在 Spark 应用中有两个职责：

- **把用户程序转换为任务**。Spark 程序其实是隐式地创建出了一个由操作组成的逻辑上的*有向无环图（Directed Acyclic Graph，简称 DAG）*。当驱动器程序运行时，它会把这个逻辑图转为物理执行计划。Spark 会对逻辑执行计划作一些优化，比如将连续的映射转为流水线化执行，将多个操作合并到一个步骤中等。这样 Spark 就把逻辑计划转为一系列*步骤（stage）*。而每个步骤又由多个*任务 (task)* 组成。这些任务会被打包并送到集群中。任务是 Spark 中最小的工作单元，用户程序通常要启动成百上千的独立任务。
- **为执行器节点调度任务**。 


