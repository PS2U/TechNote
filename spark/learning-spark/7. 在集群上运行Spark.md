Spark 可以在各种各样的集群管理器（Hadoop YARN、Apache Mesos，还有 Spark 自带的独立集群管理器）上运行，所以 Spark 应用既能够适应专用集群，又能用于共享的云计算环境。

# 7.2 Spark 运行时架构

![](img/chap7/img0.png)

在分布式环境下，Spark 集群采用的是**主/从**结构。在一个 Spark 集群中，有一个节点负责中央协调，调度各个分布式工作节点。这个中央协调节点被称为驱动器 （Driver）节点，与之对应的工作节点被称为执行器 （executor）节点。驱动器节点可以和大量的执行器节点进行通信，它们也都作为独立的 Java 进程运行。驱动器节点和所有的执行器节点一起被称为一个 Spark 应用 （application）。

Spark 应用通过一个叫作集群管理器 （Cluster Manager）的外部服务在集群中的机器上启动。Spark 自带的集群管理器被称为独立集群管理器。Spark 也能运行在 Hadoop YARN 和 Apache Mesos 这两大开源集群管理器上。

## 7.2.1 驱动器节点

Spark 驱动器是执行你的程序中的 `main()` 方法的进程。它执行用户编写的用来创建 SparkContext、创建 RDD，以及进行 RDD 的转化操作和行动操作的代码。其实，当你启动 Spark shell 时，你就启动了一个 Spark 驱动器程序。驱动器程序一旦终止，Spark 应用也就结束了。

驱动器程序在 Spark 应用中有两个职责：

- **把用户程序转换为任务**。

  Spark 程序其实是隐式地创建出了一个由操作组成的逻辑上的*有向无环图（Directed Acyclic Graph，简称 DAG）*。当驱动器程序运行时，它会把这个逻辑图转为物理执行计划。Spark 会对逻辑执行计划作一些优化，比如将连续的映射转为流水线化执行，将多个操作合并到一个步骤中等。这样 Spark 就把逻辑计划转为一系列*步骤（stage）*。而每个步骤又由多个*任务 (task)* 组成。这些任务会被打包并送到集群中。任务是 Spark 中最小的工作单元，用户程序通常要启动成百上千的独立任务。

- **为执行器节点调度任务**。

  执行器进程启动后，会向驱动器进程注册自己。因此，驱动器进程始终对应用中所有的执行器节点有完整的记录。每个执行器节点代表一个能够处理任务和存储 RDD 数据的进程。

  Spark 驱动器程序会根据当前的执行器节点集合，尝试把所有任务*基于数据所在位置*分配给合适的执行器进程。当任务执行时，执行器进程会把缓存数据存储起来，而驱动器进程同样会跟踪这些缓存数据的位置，并且利用这些位置信息来调度以后的任务，以尽量减少数据的网络传输。

  驱动器程序会将一些 Spark 应用的运行时的信息通过网页界面呈现出来，默认在端口 4040。

## 7.2.2 执行器节点

Spark 执行器节点是一种工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，执行器节点就被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有执行器节点发生了异常或崩溃，Spark 应用也可以继续执行。

执行器进程有两大作用：

- 负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；
- 通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在执行器进程内的，因此任务可以在运行时充分利用缓存数据加速运算。

## 7.2.3 集群管理器

Spark 依赖于集群管理器来启动执行器节点，而在某些特殊情况下，也依赖集群管理器来启动驱动器节点。集群管理器是 Spark 中的可插拔式组件。除了 Spark 自带的独立集群管理器，Spark 也可以运行在其他外部集群管理器上，比如 YARN 和 Mesos。

## 7.2.4 启动一个程序

不论你使用的是哪一种集群管理器，`spark-submit` 都可以你的应用提交到那种集群管理器上，并通过不同的配置选项控制应用所使用的资源数量。

## 7.2.5 小结

在集群上运行 Spark 应用的详细过程：

1. 用户通过 `spark-submit` 脚本提交应用。
2. `spark-submit` 脚本启动驱动器程序，调用用户定义的 `main()` 方法。
3. 驱动器程序与集群管理器通信，申请资源以启动执行器节点。
4. 集群管理器为驱动器程序启动执行器节点。
5. 驱动器进程执行用户应用中的操作。根据程序中所定义的对 RDD 的转化操作和行动操作，驱动器节点把工作以任务的形式发送到执行器进程。
6. 任务在执行器程序中进行计算并保存结果。
7. 如果驱动器程序的 `main()` 方法退出，或者调用了 `SparkContext.stop()` ，驱动器程序会终止执行器进程，并且通过集群管理器释放资源。

# 7.3 使用 `spark-submit` 部署

```shell 
bin/spark-submit [options] <app jar | python file> [app options]
```

> [options] 是要传给 spark-submit 的选项列表。
>
> \<app jar | python File> 表示包含应用入口的 JAR 包或 Python 脚本。
>
> [app options] 是传给你的应用的选项。如果你的程序要处理传给 `main()` 方法的参数，它只会得到 [app options] 对应的标记，不会得到 spark-submit 的标记。

`spark-submit`的一些常用选项：

| 选项                  | 描述                                       |
| ------------------- | ---------------------------------------- |
| `--master`          | 要连接的集群管理器                                |
| `--deploy-mode`     | 选择在本地（客户端“client”）启动驱动器程序，还是在集群中的一台工作节点机器（集群“cluster”）上启动。 |
| `--class`           | 运行Scala的主类                               |
| `--name`            | 应用的显示名，在Spark的网页界面                       |
| `--jars`            | 需要上传并放到应用的 CLASSPATH 中的 JAR 包的列表。如果应用依赖于少量第三方的 JAR 包，可以把它们放在这个参数里 |
| `--files`           | 需要放到应用工作目录中的文件的列表。这个参数一般用来放需要分发到各节点的数据文件 |
| `--executor-memory` | 执行器进程使用的内存大小                             |
| `--driver-memory`   | 驱动器进程使用的内存大小                             |

`spark-submit` 还允许通过 `--conf prop=value` 标记设置任意的 SparkConf 配置选项，也可以使用 `--properties-File `指定一个包含键值对的属性文件。

# 7.4 打包代码与依赖

# 导航

[目录](README.md)

上一章：[6. Spark编程进阶](6. Spark编程进阶.md)

下一章：
