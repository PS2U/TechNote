RDD是分布式的元素集合。在Spark中，对数据的所有操作无外乎是创建RDD、转换已有的RDD以及调用RDD操作进行求值。在这一切的背后，Spark会自动将RDD中的数据分发到集群上，并将操作并行化执行。

# 3.1 RDD基础

Spark中的RDD是一个不可变的分布式对象集合。每个RDD都被分为多个分区，这些分区运行在集群中的不同节点上。RDD可以包含Python、Java、Scala中的任意类型的对象，甚至可以包含用户自定义的对象。

用户有两种方法创建RDD：

- 读取一个外部数据集（如 `lines = sc.textFile("README.md"）`）
- 在驱动程序里分发驱动程序的对象集合（如`list`和`set`）

创建之后，RDD支持两种类型的操作：

- 转换操作
- 行动操作


