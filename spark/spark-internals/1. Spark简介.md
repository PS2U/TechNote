Apache Spark 是一种快速、通用、可扩展的大数据分析引擎，集批处理、实时流处理、交互式查询与图计算于一体。

# 1.1 Spark 的技术背景

现有的大多数集群计算系统都是基于非循环的数据流模型。即从稳定的物理存储（如分布式文件系统）中加载记录，记录被传入由一组确定性操作组成的DAG（Directed Acyclic Graph，有向无环图），然后写回稳定存储。DAG能够保证任务的调度和故障恢复。数据流不支持工作集，所以需要将数据输出到磁盘，每次查询时重新加载。

Spark实现了分布式的内存抽象，即RDD（Resilient Distributed Dataset，分布式数据集），支持工作集的应用，且具有数据流模型的优点：自动容错、位置感知性调度和可伸缩性。RDD运行用户在执行多个查询时将工作集缓存在内存中重用。

RDD是高度受限的共享内存模型：RDD是只读记录分区的集合。只能通过其他RDD的转换操作创建。RDD通过Lineage来重建丢失的分区：一个RDD中包含了如果从其他RDD衍生所必须的相关信息，不需要检查点操作就可以重建丢失的数据分区。

# 1.2 Spark 的优点

- 速度，基于内存。
- 易用，支持Java、Scala、Python的API，还有各种高级算法。
- 通用，批处理、Spark SQL、Spark Streaming、Spark MLlib、Spark GraphX。
- 可融合，方便与其他开源产品结合使用。如YARN、Mesos、HDFS、HBase、Cassandra。

# 1.3 Spark 架构综述

