RDD 是 Spark 最基本的抽象。它具备容错性、基于内存。

# 3.1 概述

分布式数据集的容错性有两种方式实现：

- 数据检查点。通过网络连接在机器之间复制数据，而网络带宽比内存带宽低很多。
- 记录数据的更新。RDD 选择此种方式，如果更新太多，记录更新的成本也不低。所以RDD只支持粗粒度转换，即在大量纪录上执行的单个操作。

# 3.2 什么是 RDD

RDD是只读的、分区记录的集合。 RDD 只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作来创建（转换）。RDD 含有如何从其他RDD中衍生出自己的相关信息，可以在部分分区数据丢失的时候，从物理存储的数据中计算出相应的RDD分区。

每个RDD有以下主要属性：

1. 一组分片（partition），即数据集的基本组成单位。每个分片都会被一个计算任务处理，并决定并行计算的粒度。

   默认的分片个数是程序所分配的CPU核心数，用户可以修改。每个分配的存储是由`BlockManager`实现，每个分区都会被逻辑映射为一个Block，这个Block会被一个Task负责计算。

2. 一个计算每个分区的函数。

3. RDD之间的依赖关系。

4. 一个Partitioner，即RDD的分片函数。Spark实现了两种分片函数，一个是基于哈希的`HashPartitioner`，另一个是基于范围的`RangePartitioner`。只有对key-value的RDD，才有Partitioner。Partitioner不仅决定了RDD本身的分片数量，也决定了parent RDD Shuffle输出的分片数量。

5. 一个列表，存储存取每个Partition的优先位置。这是遵循『移动数据步不如移动计算』的理念。

## 3.2.1 RDD 的创建

有两种方式可以创建RDD：

1. 从一个已经存在的Scala集合。
2. 由外部存储系统的数据集，包括本地文件系统、HDFS、HBase、Cassandra、S3等。

RDD 支持两种操作：

1. 转换（transformation），即从现有的数据集创建一个新的数据集。
2. 动作（action），即在数据集上进行计算后，返回一个值给Driver。

## 3.2.2 RDD 的转换

RDD中的转换都是惰性的，它们不会立即计算结果，而是发生一个action时，这些转换才被执行。

