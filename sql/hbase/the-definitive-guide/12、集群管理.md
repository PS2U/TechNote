# 12.1 运维任务

用户可以在指定节点的 HBase 目录下停止一个 region server：

```shell
hbase-daemon.sh stop regionserver
```

如果关闭节点时负载均衡还在运行过，则在负载均衡和 master 恢复刚才下线的 region server 之间存在竞争。要避免这种情况，要先禁用负载均衡：

```
hbase> balance_switch false
```

HBase 0.90.2 引入了一种可以让 region server 逐渐减少其负载并停止服务的方法，这项功能借助`graceful_stop.sh`完成。

## 12.1.2 滚动重启

`graceful_stop.sh`脚本也可以用来重启服务器，并将之前属于它的 region 移回原位。最简单的滚动重启：

```shell
for i in 'cat /conf/regionservers|sort';do ./bin/graceful_stop.sh \
--restart --reload --debug $i; done &> /tmp/log.txt &
```

## 12.1.3 新增服务器

### 伪分布模式

- 添加本地备份 maser：`local-master-backup.sh start 1`
- 添加本地 region server：`local-region-regionservers start 1`

### 完全分布式集群

**添加一个备份 master**。master 进程使用 ZooKeeper 协商哪一个是当前活动的进程：ZooKeeper 中有一个所有 master 进程都会竞争的专用 znode。
```shell
hbase-daemon.sh start master --backup
```

不加`--backup`参数的启动的 master 会在 ZooKeeper 中创建`/hbase/master`这个 znode。一旦创建完成，新启动的备份 master 会进入轮徐选举阶段。

从 0.90.x 开始，用户可以在`conf`目录下添加`backup-masters`文件来指定备份服务器。

**添加 region server**。首先修改`conf`目录下的 `regionservers`文件 。修改配置文件后，还要将其复制到集群中的所有机器上。然后
```shell
hbase-daemon.sh start regionserver
```

新启动的 region server，会使用自己的主机名在 ZooKeeper 中创建对应的 znode 来注册，然后会加入集群，以及被分配 region。


# 12.2 数据任务

## 12.2.1 导入/导出

HBase 有一些工具，可以将表写入 HDFS 文件中，然后再载入它们。这些工具可以用`hadoop jar`查看：

```shell
hadoop jar $HBASE_HOME/hbase-0.91.0-SNAPSHOT.jar
```

## 12.2.2 CopyTable 工具

CopyTable 被用来引导集群的复制。

```shell
hadoop jar $HBASE_HOME/hbase-0.91.0-SNAPSHOT.jar copytable
```

## 12.2.3 批量导入

HBase 有多种导入数据的方法，最直接的两种，一是 MapReduce 的`TableOutputFormat`类，另一种是使用普通的客户端 API。

一种高效的方式是批量导入（bulkimport）。批量导入使用一个 MapReduce 作业将表数据输出为 HBase 内部数据格式。

1. 准备数据。使用 `HFileOutputFormat`的 MapReduce 作业来生成 HBase 数据文件。
2. 载入数据。使用`completebulkload`工具将数据载入到集群。

HBase 有个命令行工具 `importtsv`，它可以使用制表符拆分数据格式的文件执行批量导入。

## 12.2.4 复制

1. 修改`conf`目录下的`hbase-site.xml`为整个集群打开复制功能。
2. `add_peer` 


# 12.3 额外的任务





# 导航

[目录](README.md)

上一章：[11、性能优化](11、性能优化.md)

下一章：
