Elasticsearch 使用 Lucene (开源全文检索库) 进行索引和搜索。

# 1.1 Apache Lucene 简介

Lucene 成熟、高性能、可扩展、轻量级以及强大的功能而广受青睐。Lucene 内核可以创建为独立的Java库且不依赖第三方代码，用户可以使用它提供的所见即所得的全文检索功能进行索引和搜索操作。

Lucene 还有很多扩展，如多语言处理、拼写检查、高亮显示等等。

## 1.1.2 Lucene 的总体架构

Lucene 的架构：

- 文档（document）：索引与搜索的主要数据载体，它包含一个或多个字段，存放将要写入索引或将从索引搜索出来的数据。
- 字段（field）：文档中的一个片段，它包括两个部分：字段的名称和内容。
- 词项（term）：搜索时的一个单位，代表文本中的某个词。
- 词条（token）：词项在字段中的一次出现，包括词项的文本、开始和结束的位移及类型。


Lucene 将写入索引的所有信息组织成倒排索引（inverted index）。该结构是一种将词项映射到文档的数据结构，例如：

- Elasticsearch Server （文档1）
- MasteringElasticsearch （文档2）
- Apache solr 4 Cookbook （文档3）

索引后的结构示意图如下：

| 词项            | 计数   | 文档   |
| ------------- | ---- | ---- |
| 4             | 1    | 3    |
| Apache        | 1    | 3    |
| Cookbook      | 1    | 3    |
| Elasticsearch | 2    | 1, 2 |
| Mastering     | 1    | 1    |
| Server        | 1    | 1    |
| Solr          | 1    | 3    |

实际中 Lucene 创建的索引更为复杂，索引中还包含了其他信息，如词向量（为单个字段创建的小索引，存储该字段中所有的词条）、各字段的原始信息、文档删除标记等。

每个索引由多个段（segment）组成，每个段只会被创建一次但会被查询多次。索引期间，段一经创建就不会被修改。如，文档被删除后，删除信息被单独保存在一个文件中，而段本身没有修改。

多个段可以合并在一起，成为段合并（segment merge）。段合并要么强制执行，要么由 Lucene 的内在机制原定在某个时刻进行。合并操作非常消耗I/O，且合并期间有些不再使用的信息也会被清理，例如被删除的文档。

## 1.1.3 分析你的数据

分析包括：

- 将文档中的数据转换为倒排索引，
- 将查询串转换为可用于搜索的词项。

文本分析由**分析器**执行，分析器由分词器（tokenizer）、过滤器（filter）和字符串映射器（character mapper）组成：

- 分词器：将文本切割成词条，其中包括携带各种额外信息的词项。如词项在原始文本中的位置、词项的长度等。分词器的成功是词条流，一条条地推送给过滤器处理。
- 过滤器：过滤器可以为0个或多个，用于处理词条流中的词条（移除、修改、新增词条）。Lucene提供了许多现成的过滤器：
  - 小写过滤器：将所有词条转换为小写。
  - ASCII过滤器：移除词条中的非ASCII字符。
  - 同义词过滤器：根据同义词，将一个词条转换为另一个。
  - 多语言词干还原过滤器：将词条的文本规约为其词根形式。
- 字符串映射器：调用分词器之前的文本预处理操作，如HTML文本去标签。

在索引阶段，Lucene 会根据选择的分析器来处理文档中的内容，可以根据不同的字段选择不用的分析器。检索阶段，如果使用了某个查询分析器（query parser），查询串就会被分析。*索引阶段和检索阶段到文本分析要采用相同的分析器，只有查询分析出来的词项和索引中的词项能匹配上，才会返回预期的文档集*。

## 1.1.4 Lucene 查询语言

